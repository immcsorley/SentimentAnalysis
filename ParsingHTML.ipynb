{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ae26af",
   "metadata": {},
   "source": [
    "# Parsing Scraped HTML Files\n",
    "After scraping all files, we will parse the files to collect the title, author, date, body, and category (which category on the website)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83a7a8",
   "metadata": {},
   "source": [
    "## Do not need to run this file, CSV is already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ed90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Define the path to the HTML files\n",
    "path = 'the_hill_HTML/'\n",
    "\n",
    "# Define the headers for the CSV file\n",
    "headers = ['category', 'title', 'author', 'date', 'body']\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open('the_hill_articles.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    article_count=0\n",
    "    errors=0\n",
    "\n",
    "    # Loop through each subfolder in the path\n",
    "    for category in os.listdir(path):\n",
    "        subfolder = os.path.join(path, category)\n",
    "\n",
    "        # Loop through each HTML file in the subfolder\n",
    "        for filename in os.listdir(subfolder):\n",
    "            filepath = os.path.join(subfolder, filename)\n",
    "\n",
    "            # Parse the HTML file with BeautifulSoup\n",
    "            with open(filepath) as fp:\n",
    "                soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "            # Extract the author, date, title, and body\n",
    "            try:\n",
    "                meta_section = soup.find('section', {'class': 'submitted-by | header__meta | text-transform-upper text-300 color-light-gray weight-semibold font-base desktop-only'})\n",
    "                author = meta_section.find('a').text\n",
    "                date = meta_section.find('span').text.strip().split('-')[-1].strip()\n",
    "                header_section = soup.find('section', class_='article__header')\n",
    "                title = header_section.find('h1', class_='page-title').text.strip()\n",
    "                body = soup.select_one('.article__text').text.strip()\n",
    "\n",
    "                # Write the extracted information to the CSV file\n",
    "                writer.writerow([category, title, author, date, body])\n",
    "                \n",
    "                article_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'Error extracting information from file {filepath}: {e}')\n",
    "                \n",
    "                errors+=1\n",
    "                \n",
    "    print('COMPLETE')\n",
    "    \n",
    "    print('Total Articles Collected: ', article_count)    \n",
    "    \n",
    "    print('Total Errors Collecting Articles: ', errors)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab223b4",
   "metadata": {},
   "source": [
    "### Total Articles Collected: 8436\n",
    "### Total Errors Collecting Articles: 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7f109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e564dcf",
   "metadata": {},
   "source": [
    "# After Parsing HTML files into a csv, now we tokenize the body text and generate a random sample of 2000 sentences for our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3e2b2",
   "metadata": {},
   "source": [
    "## Reading new CSV in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('the_hill_articles.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66522593",
   "metadata": {},
   "source": [
    "Many articles were missing the Author, but was replaced by the \"Facebook\" and \"twitter\" share icons, we can delete these from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f09f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['author'] == '\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nShare\\n'\n",
    "df.loc[mask, 'author'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bdd48a",
   "metadata": {},
   "source": [
    "## Tokenize body text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f8d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119f83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentences'] = df['body'].apply(sent_tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cefda1",
   "metadata": {},
   "source": [
    "## Iterating through sentences to create new df with each sentence and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9252af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the rows for the new dataframe\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through each row in the original dataframe\n",
    "for index, row in df.iterrows():\n",
    "    category = row['category'] \n",
    "    sentences = row['sentences']\n",
    "    \n",
    "    # Iterate through each sentence in the 'sentences' column\n",
    "    for sentence in sentences:\n",
    "        new_rows.append({'category': category, 'sentence': sentence})\n",
    "\n",
    "# Create the new dataframe using the new_rows list\n",
    "new_df = pd.DataFrame(new_rows, columns=['category', 'sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a855930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many weird characters in sentences, encoding these with utf-8 to try to fix\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('utf-8', 'ignore').decode('utf-8')\n",
    "\n",
    "\n",
    "new_df['sentence'] = new_df['sentence'].apply(normalize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cb4f9",
   "metadata": {},
   "source": [
    "## Getting a random sample of 2000 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b79f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = new_df.sample(n=2000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab3bef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32372</th>\n",
       "      <td>business</td>\n",
       "      <td>Someone forward you this newsletter?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133229</th>\n",
       "      <td>opinion</td>\n",
       "      <td>He was impeached (indicted, in a sense) for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204539</th>\n",
       "      <td>policy</td>\n",
       "      <td>Crypto’s market cap is sitting right around $1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47389</th>\n",
       "      <td>opinion</td>\n",
       "      <td>When it comes to fighting and ultimately defea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122803</th>\n",
       "      <td>opinion</td>\n",
       "      <td>Weapons of war, such as AR-style firearms and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200868</th>\n",
       "      <td>policy</td>\n",
       "      <td>Beyond seasonal mood changes, recent years hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165693</th>\n",
       "      <td>opinion</td>\n",
       "      <td>Transmission is occurring mainly in health car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25972</th>\n",
       "      <td>business</td>\n",
       "      <td>), whose state has legalized recreational mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133487</th>\n",
       "      <td>opinion</td>\n",
       "      <td>Carolyn Kissane, Ph.D., is assistant dean of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83170</th>\n",
       "      <td>opinion</td>\n",
       "      <td>In fact, data shows that women have been revie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           sentence\n",
       "32372   business               Someone forward you this newsletter?\n",
       "133229   opinion  He was impeached (indicted, in a sense) for th...\n",
       "204539    policy  Crypto’s market cap is sitting right around $1...\n",
       "47389    opinion  When it comes to fighting and ultimately defea...\n",
       "122803   opinion  Weapons of war, such as AR-style firearms and ...\n",
       "...          ...                                                ...\n",
       "200868    policy  Beyond seasonal mood changes, recent years hav...\n",
       "165693   opinion  Transmission is occurring mainly in health car...\n",
       "25972   business  ), whose state has legalized recreational mari...\n",
       "133487   opinion  Carolyn Kissane, Ph.D., is assistant dean of t...\n",
       "83170    opinion  In fact, data shows that women have been revie...\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae575173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to csv\n",
    "sample_df.to_csv('sample_sentences.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
